#!/usr/bin/env bun
// @bun
import j from"path";import L from"fs";import x from"bun:sqlite";import R from"fs";import E from"path";class S{version="1.0.0";db=null;dbPath;schemaPath;missions={};sorties={};locks={};events={};checkpoints={};specialists={};messages={};cursors={};constructor(K=":memory:",G){if(this.dbPath=K,G){this.schemaPath=G;return}this.schemaPath=this.resolveSchemaPath()}resolveSchemaPath(){let K=[];try{let V=new URL("",import.meta.url).pathname,Z=E.dirname(V);K.push(E.join(Z,"schema.sql"))}catch{}K.push(E.join(process.cwd(),"squawk","src","db","schema.sql"));let G=process.cwd(),H=[E.join(G,"src","db","schema.sql"),E.join(G,"db","schema.sql"),E.join(G,"lib","db","schema.sql")];K.push(...H);try{let V=Error().stack;if(V){let Z=V.match(/at.*\((.*):.*\)/);if(Z&&Z[1]){let W=E.dirname(Z[1]);K.push(E.join(W,"schema.sql")),K.push(E.join(W,"..","src","db","schema.sql"))}}}catch{}for(let V of K)if(R.existsSync(V))return V;return K[0]||E.join(process.cwd(),"squawk","src","db","schema.sql")}async initialize(){try{if(this.db=new x(this.dbPath),this.dbPath!==":memory:")this.db.exec("PRAGMA journal_mode = WAL");if(this.db.exec("PRAGMA foreign_keys = ON"),R.existsSync(this.schemaPath)){let K=R.readFileSync(this.schemaPath,"utf-8");this.db.exec(K)}else throw Error(`Schema file not found: ${this.schemaPath}`);this.initializeOperations(),console.log(`SQLite database initialized: ${this.dbPath}`)}catch(K){throw console.error("Failed to initialize database:",K),K}}initializeOperations(){if(!this.db)throw Error("Database not initialized");let K=this;K.mailboxes={version:"1.0.0",create:async(G)=>{let H=new Date().toISOString(),V=G.created_at||H,Z=G.updated_at||H;return this.db.prepare(`
          INSERT INTO mailboxes (id, created_at, updated_at)
          VALUES (?, ?, ?)
        `).run(G.id,V,Z),{id:G.id,created_at:V,updated_at:Z}},getById:async(G)=>{return this.db.prepare(`
          SELECT * FROM mailboxes WHERE id = ?
        `).get(G)||null},getAll:async()=>{return this.db.prepare(`
          SELECT * FROM mailboxes ORDER BY created_at DESC
        `).all()},update:async(G,H)=>{let V=new Date().toISOString();if(this.db.prepare(`
          UPDATE mailboxes
          SET updated_at = COALESCE(?, updated_at)
          WHERE id = ?
        `).run(V,G).changes===0)return null;return await this.mailboxes.getById(G)},delete:async(G)=>{return this.db.prepare(`
          DELETE FROM mailboxes WHERE id = ?
        `).run(G).changes>0}},this.cursors={version:"1.0.0",create:async(G)=>{let H=new Date().toISOString();return this.db.prepare(`
          INSERT INTO cursors (id, stream_id, position, consumer_id, updated_at)
          VALUES (?, ?, ?, ?, ?)
        `).run(G.id,G.stream_id,G.position,G.consumer_id,H),{id:G.id,stream_id:G.stream_id,position:G.position,consumer_id:G.consumer_id,updated_at:H}},getById:async(G)=>{return this.db.prepare(`
          SELECT * FROM cursors WHERE id = ?
        `).get(G)||null},getByStream:async(G)=>{return this.db.prepare(`
          SELECT * FROM cursors WHERE stream_id = ?
        `).get(G)||null},advance:async(G,H)=>{let V=new Date().toISOString();return this.db.prepare(`
          INSERT INTO cursors (id, stream_id, position, updated_at)
          VALUES (?, ?, ?, ?)
          ON CONFLICT(stream_id) DO UPDATE SET
            position = excluded.position,
            updated_at = excluded.updated_at
        `).run(`${G}_cursor`,G,H,V),await K.cursors.getByStream(G)},update:async(G,H)=>{let V=new Date().toISOString();return this.db.prepare(`
          UPDATE cursors
          SET position = COALESCE(?, position),
              updated_at = COALESCE(?, updated_at)
          WHERE id = ?
        `).run(H.position,V,G),await K.cursors.getById(G)},getAll:async(G)=>{let H="SELECT * FROM cursors",V=[];if(G?.stream_type)H+=" WHERE stream_id LIKE ?",V.push(`${G.stream_type}_%`);return H+=" ORDER BY updated_at DESC",this.db.prepare(H).all(...V)}},this.locks={version:"1.0.0",acquire:async(G)=>{let H=`lock_${Math.random().toString(36).substring(2,10)}`,V=new Date().toISOString(),Z=new Date(Date.now()+G.timeout_ms).toISOString(),W=this.db.prepare(`
          SELECT * FROM locks
          WHERE file = ? AND released_at IS NULL AND expires_at > datetime('now')
        `).get(G.file);if(W)return{conflict:!0,existing_lock:W};return this.db.prepare(`
          INSERT INTO locks (id, file, reserved_by, reserved_at, purpose, timeout_ms, checksum, expires_at, metadata)
          VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        `).run(H,G.file,G.specialist_id,V,G.purpose||"edit",G.timeout_ms,G.checksum,Z,JSON.stringify(G.metadata||{})),{conflict:!1,lock:{...await K.locks.getById(H),status:"active",expires_at:Z,normalized_path:G.file}}},release:async(G)=>{return this.db.prepare(`
          UPDATE locks
          SET released_at = datetime('now'),
              status = 'released'
          WHERE id = ?
        `).run(G).changes>0},getById:async(G)=>{return this.db.prepare(`
          SELECT * FROM locks WHERE id = ?
        `).get(G)||null},getByFile:async(G)=>{return this.db.prepare(`
          SELECT * FROM locks
          WHERE file = ? AND released_at IS NULL AND expires_at > datetime('now')
        `).get(G)||null},getActive:async()=>{return this.db.prepare(`
          SELECT * FROM locks
          WHERE released_at IS NULL AND expires_at > datetime('now')
        `).all().map((H)=>({...H,status:"active",normalized_path:H.file}))},getAll:async()=>{return this.db.prepare(`
          SELECT * FROM locks ORDER BY reserved_at DESC
        `).all()},forceRelease:async(G)=>{return this.db.prepare(`
          UPDATE locks
          SET released_at = datetime('now'),
              status = 'force_released'
          WHERE id = ?
        `).run(G).changes>0},getExpired:async()=>{let G=new Date().toISOString();return this.db.prepare(`
          SELECT * FROM locks
          WHERE released_at IS NULL 
            AND timeout_ms IS NOT NULL
            AND expires_at IS NOT NULL
            AND expires_at < datetime('now')
        `).all()},releaseExpired:async()=>{return this.db.prepare(`
          UPDATE locks
          SET released_at = datetime('now'),
              status = 'expired'
          WHERE released_at IS NULL 
            AND timeout_ms IS NOT NULL
            AND expires_at IS NOT NULL
            AND expires_at < datetime('now')
        `).run().changes}},this.events={version:"1.0.0",append:async(G)=>{let H=`evt_${Math.random().toString(36).substring(2,10)}`,Z=(this.db.prepare(`
          SELECT MAX(sequence_number) as last_seq
          FROM events
          WHERE stream_type = ? AND stream_id = ?
        `).get(G.stream_type,G.stream_id)?.last_seq||0)+1,W=new Date().toISOString(),F=G.stream_id;if(!this.db.prepare(`
          SELECT id FROM mailboxes WHERE id = ?
        `).get(G.stream_id))F=`mbx_${G.stream_type}_${G.stream_id}`,this.db.prepare(`
            INSERT OR IGNORE INTO mailboxes (id, created_at, updated_at)
            VALUES (?, ?, ?)
          `).run(F,W,W);return this.db.prepare(`
          INSERT INTO events (
            id, mailbox_id, type, stream_type, stream_id, sequence_number,
            data, occurred_at, causation_id, correlation_id, metadata
          ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        `).run(H,F,G.event_type,G.stream_type,G.stream_id,Z,JSON.stringify(G.data),G.occurred_at||W,G.causation_id||null,G.correlation_id||null,JSON.stringify(G.metadata||{})),{sequence_number:Z,event_id:H,event_type:G.event_type,stream_type:G.stream_type,stream_id:G.stream_id,data:G.data,causation_id:G.causation_id,correlation_id:G.correlation_id,metadata:G.metadata,occurred_at:G.occurred_at||W,recorded_at:W,schema_version:G.schema_version||1}},queryByStream:async(G,H,V)=>{let Z=`
          SELECT * FROM events
          WHERE stream_type = ? AND stream_id = ?
          ${V?"AND sequence_number > ?":""}
          ORDER BY sequence_number ASC
        `,W=[G,H];if(V!==void 0)W.push(V);return this.db.prepare(Z).all(...W).map((J)=>({sequence_number:J.sequence_number,event_id:J.id,event_type:J.type,stream_type:J.stream_type,stream_id:J.stream_id,data:JSON.parse(J.data),causation_id:J.causation_id,correlation_id:J.correlation_id,metadata:J.metadata?JSON.parse(J.metadata):void 0,occurred_at:J.occurred_at,recorded_at:J.occurred_at,schema_version:1}))},queryByType:async(G)=>{return this.db.prepare(`
          SELECT * FROM events WHERE type = ? ORDER BY occurred_at ASC
        `).all(G).map((V)=>({sequence_number:V.sequence_number,event_id:V.id,event_type:V.type,stream_type:V.stream_type,stream_id:V.stream_id,data:JSON.parse(V.data),causation_id:V.causation_id,correlation_id:V.correlation_id,metadata:V.metadata?JSON.parse(V.metadata):void 0,occurred_at:V.occurred_at,recorded_at:V.occurred_at,schema_version:1}))},getEvents:async(G)=>{let H="SELECT * FROM events WHERE 1=1",V=[];if(G.event_type)if(Array.isArray(G.event_type))H+=` AND type IN (${G.event_type.map(()=>"?").join(",")})`,V.push(...G.event_type);else H+=" AND type = ?",V.push(G.event_type);if(G.stream_type)if(Array.isArray(G.stream_type))H+=` AND stream_type IN (${G.stream_type.map(()=>"?").join(",")})`,V.push(...G.stream_type);else H+=" AND stream_type = ?",V.push(G.stream_type);if(G.stream_id)H+=" AND stream_id = ?",V.push(G.stream_id);if(G.after_sequence!==void 0)H+=" AND sequence_number > ?",V.push(G.after_sequence);return H+=" ORDER BY occurred_at ASC",this.db.prepare(H).all(...V).map((W)=>({sequence_number:W.sequence_number,event_id:W.id,event_type:W.type,stream_type:W.stream_type,stream_id:W.stream_id,data:JSON.parse(W.data),causation_id:W.causation_id,correlation_id:W.correlation_id,metadata:W.metadata?JSON.parse(W.metadata):void 0,occurred_at:W.occurred_at,recorded_at:W.occurred_at,schema_version:1}))},getLatestByStream:async(G,H)=>{let V=this.db.prepare(`
          SELECT * FROM events
          WHERE stream_type = ? AND stream_id = ?
          ORDER BY sequence_number DESC
          LIMIT 1
        `).get(G,H);return V?{sequence_number:V.sequence_number,event_id:V.id,event_type:V.type,stream_type:V.stream_type,stream_id:V.stream_id,data:JSON.parse(V.data),causation_id:V.causation_id,correlation_id:V.correlation_id,metadata:V.metadata?JSON.parse(V.metadata):void 0,occurred_at:V.occurred_at,recorded_at:V.occurred_at,schema_version:1}:null}},this.missions={},this.sorties={},this.checkpoints={},this.specialists={},this.messages={},K.checkpoints={version:"1.0.0",create:async(G)=>{let H=G.id||`chk_${Math.random().toString(36).substring(2,10)}`,V=new Date().toISOString();return this.db.prepare(`
          INSERT INTO checkpoints (
            id, mission_id, mission_title, timestamp, trigger, trigger_details,
            progress_percent, sorties, active_locks, pending_messages,
            recovery_context, created_by, expires_at, version, metadata
          ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        `).run(H,G.mission_id,G.mission_title||null,G.timestamp||V,G.trigger,G.trigger_details||null,G.progress_percent||0,JSON.stringify(G.sorties||[]),JSON.stringify(G.active_locks||[]),JSON.stringify(G.pending_messages||[]),JSON.stringify(G.recovery_context||{}),G.created_by,G.expires_at||null,G.version||"1.0.0",JSON.stringify(G.metadata||{})),await K.checkpoints.getById(H)},getById:async(G)=>{let H=this.db.prepare(`
          SELECT * FROM checkpoints WHERE id = ?
        `).get(G);if(!H)return null;return{id:H.id,mission_id:H.mission_id,mission_title:H.mission_title,timestamp:H.timestamp,trigger:H.trigger,trigger_details:H.trigger_details,progress_percent:H.progress_percent,sorties:H.sorties?JSON.parse(H.sorties):[],active_locks:H.active_locks?JSON.parse(H.active_locks):[],pending_messages:H.pending_messages?JSON.parse(H.pending_messages):[],recovery_context:H.recovery_context?JSON.parse(H.recovery_context):{},created_by:H.created_by,expires_at:H.expires_at,consumed_at:H.consumed_at,version:H.version,metadata:H.metadata?JSON.parse(H.metadata):{}}},getLatest:async(G)=>{let H=this.db.prepare(`
          SELECT * FROM checkpoints
          WHERE mission_id = ? AND consumed_at IS NULL
          ORDER BY timestamp DESC
          LIMIT 1
        `).get(G);if(!H)return null;return await K.checkpoints.getById(H.id)},list:async(G)=>{let H="SELECT * FROM checkpoints",V=[];if(G)H+=" WHERE mission_id = ?",V.push(G);return H+=" ORDER BY timestamp DESC",this.db.prepare(H).all(...V).map((W)=>({id:W.id,mission_id:W.mission_id,mission_title:W.mission_title,timestamp:W.timestamp,trigger:W.trigger,trigger_details:W.trigger_details,progress_percent:W.progress_percent,sorties:W.sorties?JSON.parse(W.sorties):[],active_locks:W.active_locks?JSON.parse(W.active_locks):[],pending_messages:W.pending_messages?JSON.parse(W.pending_messages):[],recovery_context:W.recovery_context?JSON.parse(W.recovery_context):{},created_by:W.created_by,expires_at:W.expires_at,consumed_at:W.consumed_at,version:W.version,metadata:W.metadata?JSON.parse(W.metadata):{}}))},delete:async(G)=>{return this.db.prepare(`
          DELETE FROM checkpoints WHERE id = ?
        `).run(G).changes>0},markConsumed:async(G)=>{let H=new Date().toISOString();if(this.db.prepare(`
          UPDATE checkpoints
          SET consumed_at = ?
          WHERE id = ?
        `).run(H,G).changes>0)return await K.checkpoints.getById(G);return null}}}async close(){try{if(this.db)this.db.close(),this.db=null,console.log(`SQLite database closed: ${this.dbPath}`)}catch(K){throw console.error("Error closing database:",K),K}}async isHealthy(){try{if(!this.db)return!1;return this.db.prepare("SELECT 1").get(),!0}catch{return!1}}async getStats(){if(!this.db)throw Error("Database not initialized");let K=this.db.prepare("SELECT COUNT(*) as count FROM events").get(),G=0,H=0,V=this.db.prepare("SELECT COUNT(*) as count FROM locks WHERE released_at IS NULL AND expires_at > datetime('now')").get(),Z=0,W=0,F=0;if(this.dbPath!==":memory:"&&R.existsSync(this.dbPath)){W=R.statSync(this.dbPath).size;let J=`${this.dbPath}-wal`;if(R.existsSync(J))F=R.statSync(J).size}return{total_events:K.count,total_missions:G,active_missions:H,active_locks:V.count,total_checkpoints:Z,database_size_bytes:W,wal_size_bytes:F}}async maintenance(){if(!this.db)throw Error("Database not initialized");try{this.db.exec("VACUUM"),console.log("Database maintenance completed")}catch(K){throw console.error("Error running database maintenance:",K),K}}async beginTransaction(){if(!this.db)throw Error("Database not initialized");try{this.db.exec("BEGIN TRANSACTION")}catch(K){throw console.error("Error beginning transaction:",K),K}}async commitTransaction(){if(!this.db)throw Error("Database not initialized");try{this.db.exec("COMMIT")}catch(K){throw console.error("Error committing transaction:",K),K}}async rollbackTransaction(){if(!this.db)throw Error("Database not initialized");try{this.db.exec("ROLLBACK")}catch(K){throw console.error("Error rolling back transaction:",K),K}}getDatabase(){return this.db}}var __dirname="/home/vitruvius/git/fleettools/squawk/src/db";function I(){return j.join(process.env.HOME||"",".local","share","fleet","squawk.json")}function v(){if(process.env.PORT||process.env.API_SERVER)return j.join(process.env.HOME||"",".local","share","fleet","squawk.db");return j.join(process.env.HOME||"",".local","share","fleet","squawk.db")}var Y=null;async function A(K){let G=K||v(),H=j.dirname(G);if(!L.existsSync(H))L.mkdirSync(H,{recursive:!0});let V=j.join(__dirname,"schema.sql");Y=new S(G,V),await Y.initialize();let Z=I();if(L.existsSync(Z)){await q(Z);let W=Z+".backup";L.renameSync(Z,W),console.log("[Migration] Legacy data migrated to SQLite"),console.log(`[Migration] Backup saved to: ${W}`)}}function X(){if(!Y)throw Error("Database not initialized. Call initializeDatabase() first.");return Y}async function D(){if(Y)await Y.close(),Y=null}async function q(K){console.log(`[Migration] Starting migration from: ${K}`);try{let G=L.readFileSync(K,"utf-8"),H=JSON.parse(G),V={mailboxes:0,events:0,cursors:0,locks:0};for(let[Z,W]of Object.entries(H.mailboxes||{}))try{if(!W.created_at||!W.updated_at){console.warn(`[Migration] Skipping mailbox ${Z} due to missing required fields`);continue}await Y.mailboxes.create({id:Z,created_at:W.created_at,updated_at:W.updated_at}),V.mailboxes++}catch(F){console.warn(`[Migration] Failed to migrate mailbox ${Z}:`,F)}for(let[Z,W]of Object.entries(H.events||{})){if(!await Y.mailboxes.getById(Z))await Y.mailboxes.create({id:Z,created_at:new Date().toISOString(),updated_at:new Date().toISOString()}),V.mailboxes++;for(let F of W)try{if(!F.type){console.warn(`[Migration] Skipping event without type field in mailbox ${Z}`);continue}await Y.events.append({event_type:F.type,stream_type:"squawk",stream_id:Z,data:typeof F.data==="string"?JSON.parse(F.data):F.data,occurred_at:F.occurred_at,causation_id:F.causation_id,correlation_id:F.correlation_id,metadata:F.metadata?typeof F.metadata==="string"?JSON.parse(F.metadata):F.metadata:void 0}),V.events++}catch(J){console.warn("[Migration] Failed to migrate event:",J)}}for(let[Z,W]of Object.entries(H.cursors||{}))try{await Y.cursors.create({id:Z,stream_type:"squawk",stream_id:W.stream_id,position:W.position,consumer_id:W.consumer_id||"migrated"}),V.cursors++}catch(F){console.warn(`[Migration] Failed to migrate cursor ${Z}:`,F)}for(let[Z,W]of Object.entries(H.locks||{})){let F=W;if(!F.released_at)try{await Y.locks.acquire({file:F.file,specialist_id:F.reserved_by,timeout_ms:F.timeout_ms||30000,purpose:F.purpose==="delete"?"delete":F.purpose==="read"?"read":"edit",checksum:F.checksum}),V.locks++}catch(J){console.warn(`[Migration] Failed to migrate lock ${Z}:`,J)}}console.log("[Migration] Complete:"),console.log(`  - Mailboxes: ${V.mailboxes}`),console.log(`  - Events: ${V.events}`),console.log(`  - Cursors: ${V.cursors}`),console.log(`  - Locks: ${V.locks}`)}catch(G){throw console.error("[Migration] Failed:",G),G}}var z={getAll:async()=>{return(await X().mailboxes.getAll()).sort((H,V)=>new Date(V.created_at).getTime()-new Date(H.created_at).getTime())},getById:async(K)=>{return X().mailboxes.getById(K)},create:async(K)=>{let G=X(),H=new Date().toISOString();return G.mailboxes.create({id:K,created_at:H,updated_at:H})},exists:async(K)=>{return await X().mailboxes.getById(K)!==null}},O={getByMailbox:async(K)=>{return(await X().events.queryByStream("squawk",K)).sort((V,Z)=>new Date(V.occurred_at).getTime()-new Date(Z.occurred_at).getTime())},append:async(K,G)=>{let H=X();if(!await H.mailboxes.getById(K))await H.mailboxes.create({id:K,created_at:new Date().toISOString(),updated_at:new Date().toISOString()});let V=[];for(let Z of G){let W=await H.events.append({event_type:Z.type,stream_type:"squawk",stream_id:K,data:typeof Z.data==="string"?JSON.parse(Z.data):Z.data,occurred_at:Z.occurred_at,causation_id:Z.causation_id,correlation_id:Z.correlation_id,metadata:Z.metadata?typeof Z.metadata==="string"?JSON.parse(Z.metadata):Z.metadata:void 0});V.push(W)}return V}},_={getById:async(K)=>{return X().cursors.getById(K)},getByStream:async(K)=>{return(await X().cursors.getAll()).find((V)=>V.stream_id===K)||null},upsert:async(K)=>{let G=X(),H=K.id||`${K.stream_id}_cursor`,V=new Date().toISOString(),Z=await G.cursors.getById(H);if(Z)return await G.cursors.update(H,{position:K.position,updated_at:V}),Z;else return G.cursors.create({id:H,stream_type:"squawk",stream_id:K.stream_id,position:K.position,consumer_id:K.consumer_id||"default"})}},M={getAll:async()=>{let G=await X().locks.getAll(),H=new Date().toISOString();return G.filter((V)=>{if(V.status==="released")return!1;return V.expires_at>H})},getById:async(K)=>{return X().locks.getById(K)},acquire:async(K)=>{let H=await X().locks.acquire({file:K.file,specialist_id:K.reserved_by||K.specialist_id,timeout_ms:K.timeout_ms||30000,purpose:K.purpose==="delete"?"delete":K.purpose==="read"?"read":"edit",checksum:K.checksum});if(H.conflict)return H.existing_lock||{id:H.lock?.id||"",file:K.file,reserved_by:H.lock?.reserved_by||"",reserved_at:H.lock?.reserved_at||"",released_at:null,purpose:K.purpose||"edit",checksum:K.checksum,timeout_ms:K.timeout_ms||30000,metadata:K.metadata};return H.lock},release:async(K)=>{let G=X(),H=await G.locks.getById(K);if(H)return await G.locks.release(K),H;return null},getExpired:async()=>{let G=await X().locks.getAll(),H=new Date().toISOString();return G.filter((V)=>{if(V.status==="released")return!1;return V.expires_at<=H})},releaseExpired:async()=>{let K=await M.getExpired();for(let G of K)await M.release(G.id);return K.length}};async function g(K={}){let G=K.port||parseInt(process.env.SQUAWK_PORT||"3000",10);await A(),console.log("Squawk API database initialized");let H=Bun.serve({port:G,async fetch(W){let J=new URL(W.url).pathname,U={"Access-Control-Allow-Origin":"*","Access-Control-Allow-Methods":"GET, POST, PUT, DELETE, OPTIONS","Access-Control-Allow-Headers":"Content-Type"};if(W.method==="OPTIONS")return new Response(null,{headers:U});if(J==="/health")return new Response(JSON.stringify({status:"healthy",service:"squawk",timestamp:new Date().toISOString()}),{headers:{...U,"Content-Type":"application/json"}});if(J==="/api/v1/mailbox/append"&&W.method==="POST")try{let $=await W.json(),{stream_id:B,events:N}=$;if(!B||!Array.isArray(N))return new Response(JSON.stringify({error:"stream_id and events array are required"}),{status:400,headers:{...U,"Content-Type":"application/json"}});if(!await z.exists(B))await z.create(B);let Q=N.map((T)=>({type:T.type,stream_id:B,data:JSON.stringify(T.data),occurred_at:new Date().toISOString(),causation_id:T.causation_id||null,metadata:T.metadata?JSON.stringify(T.metadata):null})),C=await O.append(B,Q),y=await z.getById(B),P=await O.getByMailbox(B);return new Response(JSON.stringify({mailbox:{...y,events:P},inserted:C.length}),{headers:{...U,"Content-Type":"application/json"}})}catch($){console.error("Error appending to mailbox:",$),K.onRequestError?.($);let B=$ instanceof Error?$.message:String($);return new Response(JSON.stringify({error:"Failed to append to mailbox",details:B}),{status:500,headers:{...U,"Content-Type":"application/json"}})}if(J.startsWith("/api/v1/mailbox/")&&W.method==="GET"){let $=J.split("/").pop();if(!$)return new Response(JSON.stringify({error:"Invalid stream ID"}),{status:400,headers:{...U,"Content-Type":"application/json"}});try{let B=await z.getById($);if(!B)return new Response(JSON.stringify({error:"Mailbox not found"}),{status:404,headers:{...U,"Content-Type":"application/json"}});let N=await O.getByMailbox($);return new Response(JSON.stringify({mailbox:{...B,events:N}}),{headers:{...U,"Content-Type":"application/json"}})}catch(B){return console.error("Error getting mailbox:",B),K.onRequestError?.(B),new Response(JSON.stringify({error:"Failed to get mailbox"}),{status:500,headers:{...U,"Content-Type":"application/json"}})}}if(J==="/api/v1/cursor/advance"&&W.method==="POST")try{let $=await W.json(),{stream_id:B,position:N}=$;if(!B||typeof N!=="number")return new Response(JSON.stringify({error:"stream_id and position are required"}),{status:400,headers:{...U,"Content-Type":"application/json"}});if(!await z.exists(B))await z.create(B);let Q=await _.upsert({stream_id:B,position:N,updated_at:new Date().toISOString()});return new Response(JSON.stringify({cursor:Q}),{headers:{...U,"Content-Type":"application/json"}})}catch($){return console.error("Error advancing cursor:",$),K.onRequestError?.($),new Response(JSON.stringify({error:"Failed to advance cursor"}),{status:500,headers:{...U,"Content-Type":"application/json"}})}if(J.startsWith("/api/v1/cursor/")&&W.method==="GET"){let $=J.split("/").pop();if(!$)return new Response(JSON.stringify({error:"Invalid cursor ID"}),{status:400,headers:{...U,"Content-Type":"application/json"}});try{let B=await _.getById($);if(!B)return new Response(JSON.stringify({error:"Cursor not found"}),{status:404,headers:{...U,"Content-Type":"application/json"}});return new Response(JSON.stringify({cursor:B}),{headers:{...U,"Content-Type":"application/json"}})}catch(B){return console.error("Error getting cursor:",B),K.onRequestError?.(B),new Response(JSON.stringify({error:"Failed to get cursor"}),{status:500,headers:{...U,"Content-Type":"application/json"}})}}if(J==="/api/v1/lock/acquire"&&W.method==="POST")try{let $=await W.json(),{file:B,specialist_id:N,timeout_ms:Q=30000}=$;if(!B||!N)return new Response(JSON.stringify({error:"file and specialist_id are required"}),{status:400,headers:{...U,"Content-Type":"application/json"}});let C=await M.acquire({file:B,reserved_by:N,reserved_at:new Date().toISOString(),released_at:null,purpose:"edit",checksum:null,timeout_ms:Q,metadata:null});return new Response(JSON.stringify({lock:C}),{headers:{...U,"Content-Type":"application/json"}})}catch($){return console.error("Error acquiring lock:",$),K.onRequestError?.($),new Response(JSON.stringify({error:"Failed to acquire lock"}),{status:500,headers:{...U,"Content-Type":"application/json"}})}if(J==="/api/v1/lock/release"&&W.method==="POST")try{let $=await W.json(),{lock_id:B,specialist_id:N}=$;if(!B)return new Response(JSON.stringify({error:"lock_id is required"}),{status:400,headers:{...U,"Content-Type":"application/json"}});let Q=await M.getById(B);if(!Q)return new Response(JSON.stringify({error:"Lock not found"}),{status:404,headers:{...U,"Content-Type":"application/json"}});if(Q.reserved_by!==N)return new Response(JSON.stringify({error:"Cannot release lock: wrong specialist"}),{status:403,headers:{...U,"Content-Type":"application/json"}});let C=await M.release(B);return new Response(JSON.stringify({lock:C}),{headers:{...U,"Content-Type":"application/json"}})}catch($){return console.error("Error releasing lock:",$),K.onRequestError?.($),new Response(JSON.stringify({error:"Failed to release lock"}),{status:500,headers:{...U,"Content-Type":"application/json"}})}if(J==="/api/v1/locks"&&W.method==="GET")try{let $=await M.getAll();return new Response(JSON.stringify({locks:$}),{headers:{...U,"Content-Type":"application/json"}})}catch($){return console.error("Error listing locks:",$),K.onRequestError?.($),new Response(JSON.stringify({error:"Failed to list locks"}),{status:500,headers:{...U,"Content-Type":"application/json"}})}if(J==="/api/v1/coordinator/status"&&W.method==="GET")try{let $=await z.getAll(),B=await M.getAll();return new Response(JSON.stringify({active_mailboxes:$.length,active_locks:B.length,timestamp:new Date().toISOString()}),{headers:{...U,"Content-Type":"application/json"}})}catch($){console.error("Error getting coordinator status:",$),K.onRequestError?.($);let B=$ instanceof Error?$.message:String($);return new Response(JSON.stringify({error:"Failed to get status",details:B}),{status:500,headers:{...U,"Content-Type":"application/json"}})}return new Response(JSON.stringify({error:"Not found"}),{status:404,headers:{...U,"Content-Type":"application/json"}})}}),V=setInterval(async()=>{let W=await M.releaseExpired();if(W>0)console.log(`Released ${W} expired locks`)},30000);console.log(`Squawk API server listening on port ${H.port}`),console.log("Endpoints:"),console.log("  POST   /api/v1/mailbox/append   - Append events to mailbox"),console.log("  GET    /api/v1/mailbox/:streamId - Get mailbox contents"),console.log("  POST   /api/v1/cursor/advance   - Advance cursor position"),console.log("  GET    /api/v1/cursor/:cursorId - Get cursor position"),console.log("  POST   /api/v1/lock/acquire     - Acquire file lock (CTK)"),console.log("  POST   /api/v1/lock/release    - Release file lock (CTK)"),console.log("  GET    /api/v1/locks               - List all active locks"),console.log("  GET    /api/v1/coordinator/status - Get coordinator status"),console.log("  GET    /health                     - Health check");let Z=(W)=>{console.log(`Received ${W}, shutting down...`),clearInterval(V),D(),H.stop(),process.exit(0)};process.on("SIGINT",()=>Z("SIGINT")),process.on("SIGTERM",()=>Z("SIGTERM")),K.onReady?.(H.port)}g({port:parseInt(process.env.SQUAWK_PORT||"3000",10),onReady:(K)=>{console.log(`Squawk server is ready on port ${K}`)},onRequestError:(K)=>{console.error("Request error:",K)}}).catch((K)=>{console.error("Failed to start Squawk server:",K),process.exit(1)});
