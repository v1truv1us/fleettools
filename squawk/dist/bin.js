#!/usr/bin/env bun
// @bun
import R from"path";import N from"fs";import I from"bun:sqlite";import T from"fs";import F from"path";class S{version="1.0.0";db=null;dbPath;schemaPath;missions={};sorties={};locks={};events={};checkpoints={};specialists={};messages={};cursors={};constructor(K=":memory:",G){if(this.dbPath=K,G){this.schemaPath=G;return}this.schemaPath=this.resolveSchemaPath()}resolveSchemaPath(){let K=[];try{let V=new URL("",import.meta.url).pathname,Z=F.dirname(V);K.push(F.join(Z,"schema.sql"))}catch{}K.push(F.join(process.cwd(),"squawk","src","db","schema.sql"));let G=process.cwd(),H=[F.join(G,"src","db","schema.sql"),F.join(G,"db","schema.sql"),F.join(G,"lib","db","schema.sql")];K.push(...H);try{let V=Error().stack;if(V){let Z=V.match(/at.*\((.*):.*\)/);if(Z&&Z[1]){let W=F.dirname(Z[1]);K.push(F.join(W,"schema.sql")),K.push(F.join(W,"..","src","db","schema.sql"))}}}catch{}for(let V of K)if(T.existsSync(V))return V;return K[0]||F.join(process.cwd(),"squawk","src","db","schema.sql")}async initialize(){try{if(this.db=new I(this.dbPath),this.dbPath!==":memory:")this.db.exec("PRAGMA journal_mode = WAL");if(this.db.exec("PRAGMA foreign_keys = ON"),T.existsSync(this.schemaPath)){let K=T.readFileSync(this.schemaPath,"utf-8");this.db.exec(K)}else throw Error(`Schema file not found: ${this.schemaPath}`);this.initializeOperations(),console.log(`SQLite database initialized: ${this.dbPath}`)}catch(K){throw console.error("Failed to initialize database:",K),K}}initializeOperations(){if(!this.db)throw Error("Database not initialized");let K=this;K.mailboxes={version:"1.0.0",create:async(G)=>{let H=new Date().toISOString(),V=G.created_at||H,Z=G.updated_at||H;return this.db.prepare(`
          INSERT INTO mailboxes (id, created_at, updated_at)
          VALUES (?, ?, ?)
        `).run(G.id,V,Z),{id:G.id,created_at:V,updated_at:Z}},getById:async(G)=>{return this.db.prepare(`
          SELECT * FROM mailboxes WHERE id = ?
        `).get(G)||null},getAll:async()=>{return this.db.prepare(`
          SELECT * FROM mailboxes ORDER BY created_at DESC
        `).all()},update:async(G,H)=>{let V=new Date().toISOString();if(this.db.prepare(`
          UPDATE mailboxes
          SET updated_at = COALESCE(?, updated_at)
          WHERE id = ?
        `).run(V,G).changes===0)return null;return await this.mailboxes.getById(G)},delete:async(G)=>{return this.db.prepare(`
          DELETE FROM mailboxes WHERE id = ?
        `).run(G).changes>0}},this.cursors={version:"1.0.0",create:async(G)=>{let H=new Date().toISOString();return this.db.prepare(`
          INSERT INTO cursors (id, stream_id, position, consumer_id, updated_at)
          VALUES (?, ?, ?, ?, ?)
        `).run(G.id,G.stream_id,G.position,G.consumer_id,H),{id:G.id,stream_id:G.stream_id,position:G.position,consumer_id:G.consumer_id,updated_at:H}},getById:async(G)=>{return this.db.prepare(`
          SELECT * FROM cursors WHERE id = ?
        `).get(G)||null},getByStream:async(G)=>{return this.db.prepare(`
          SELECT * FROM cursors WHERE stream_id = ?
        `).get(G)||null},advance:async(G,H)=>{let V=new Date().toISOString();return this.db.prepare(`
          INSERT INTO cursors (id, stream_id, position, updated_at)
          VALUES (?, ?, ?, ?)
          ON CONFLICT(stream_id) DO UPDATE SET
            position = excluded.position,
            updated_at = excluded.updated_at
        `).run(`${G}_cursor`,G,H,V),await K.cursors.getByStream(G)},update:async(G,H)=>{let V=new Date().toISOString();return this.db.prepare(`
          UPDATE cursors
          SET position = COALESCE(?, position),
              updated_at = COALESCE(?, updated_at)
          WHERE id = ?
        `).run(H.position,V,G),await K.cursors.getById(G)},getAll:async(G)=>{let H="SELECT * FROM cursors",V=[];if(G?.stream_type)H+=" WHERE stream_id LIKE ?",V.push(`${G.stream_type}_%`);return H+=" ORDER BY updated_at DESC",this.db.prepare(H).all(...V)}},this.locks={version:"1.0.0",acquire:async(G)=>{let H=`lock_${Math.random().toString(36).substring(2,10)}`,V=new Date().toISOString(),Z=new Date(Date.now()+G.timeout_ms).toISOString(),W=this.db.prepare(`
          SELECT * FROM locks
          WHERE file = ? AND released_at IS NULL AND expires_at > datetime('now')
        `).get(G.file);if(W)return{conflict:!0,existing_lock:W};return this.db.prepare(`
          INSERT INTO locks (id, file, reserved_by, reserved_at, purpose, timeout_ms, checksum, expires_at, metadata)
          VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        `).run(H,G.file,G.specialist_id,V,G.purpose||"edit",G.timeout_ms,G.checksum,Z,JSON.stringify(G.metadata||{})),{conflict:!1,lock:{...await K.locks.getById(H),status:"active",expires_at:Z,normalized_path:G.file}}},release:async(G)=>{return this.db.prepare(`
          UPDATE locks
          SET released_at = datetime('now'),
              status = 'released'
          WHERE id = ?
        `).run(G).changes>0},getById:async(G)=>{return this.db.prepare(`
          SELECT * FROM locks WHERE id = ?
        `).get(G)||null},getByFile:async(G)=>{return this.db.prepare(`
          SELECT * FROM locks
          WHERE file = ? AND released_at IS NULL AND expires_at > datetime('now')
        `).get(G)||null},getActive:async()=>{return this.db.prepare(`
          SELECT * FROM locks
          WHERE released_at IS NULL AND expires_at > datetime('now')
        `).all().map((H)=>({...H,status:"active",normalized_path:H.file}))},getAll:async()=>{return this.db.prepare(`
          SELECT * FROM locks ORDER BY reserved_at DESC
        `).all()},forceRelease:async(G)=>{return this.db.prepare(`
          UPDATE locks
          SET released_at = datetime('now'),
              status = 'force_released'
          WHERE id = ?
        `).run(G).changes>0},getExpired:async()=>{let G=new Date().toISOString();return this.db.prepare(`
          SELECT * FROM locks
          WHERE released_at IS NULL 
            AND timeout_ms IS NOT NULL
            AND expires_at IS NOT NULL
            AND expires_at < datetime('now')
        `).all()},releaseExpired:async()=>{return this.db.prepare(`
          UPDATE locks
          SET released_at = datetime('now'),
              status = 'expired'
          WHERE released_at IS NULL 
            AND timeout_ms IS NOT NULL
            AND expires_at IS NOT NULL
            AND expires_at < datetime('now')
        `).run().changes}},this.events={version:"1.0.0",append:async(G)=>{let H=`evt_${Math.random().toString(36).substring(2,10)}`,Z=(this.db.prepare(`
          SELECT MAX(sequence_number) as last_seq
          FROM events
          WHERE stream_type = ? AND stream_id = ?
        `).get(G.stream_type,G.stream_id)?.last_seq||0)+1,W=new Date().toISOString(),B=G.stream_id;if(!this.db.prepare(`
          SELECT id FROM mailboxes WHERE id = ?
        `).get(G.stream_id))B=`mbx_${G.stream_type}_${G.stream_id}`,this.db.prepare(`
            INSERT OR IGNORE INTO mailboxes (id, created_at, updated_at)
            VALUES (?, ?, ?)
          `).run(B,W,W);return this.db.prepare(`
          INSERT INTO events (
            id, mailbox_id, type, stream_type, stream_id, sequence_number,
            data, occurred_at, causation_id, correlation_id, metadata
          ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        `).run(H,B,G.event_type,G.stream_type,G.stream_id,Z,JSON.stringify(G.data),G.occurred_at||W,G.causation_id||null,G.correlation_id||null,JSON.stringify(G.metadata||{})),{sequence_number:Z,event_id:H,event_type:G.event_type,stream_type:G.stream_type,stream_id:G.stream_id,data:G.data,causation_id:G.causation_id,correlation_id:G.correlation_id,metadata:G.metadata,occurred_at:G.occurred_at||W,recorded_at:W,schema_version:G.schema_version||1}},queryByStream:async(G,H,V)=>{let Z=`
          SELECT * FROM events
          WHERE stream_type = ? AND stream_id = ?
          ${V?"AND sequence_number > ?":""}
          ORDER BY sequence_number ASC
        `,W=[G,H];if(V!==void 0)W.push(V);return this.db.prepare(Z).all(...W).map((U)=>({sequence_number:U.sequence_number,event_id:U.id,event_type:U.type,stream_type:U.stream_type,stream_id:U.stream_id,data:JSON.parse(U.data),causation_id:U.causation_id,correlation_id:U.correlation_id,metadata:U.metadata?JSON.parse(U.metadata):void 0,occurred_at:U.occurred_at,recorded_at:U.occurred_at,schema_version:1}))},queryByType:async(G)=>{return this.db.prepare(`
          SELECT * FROM events WHERE type = ? ORDER BY occurred_at ASC
        `).all(G).map((V)=>({sequence_number:V.sequence_number,event_id:V.id,event_type:V.type,stream_type:V.stream_type,stream_id:V.stream_id,data:JSON.parse(V.data),causation_id:V.causation_id,correlation_id:V.correlation_id,metadata:V.metadata?JSON.parse(V.metadata):void 0,occurred_at:V.occurred_at,recorded_at:V.occurred_at,schema_version:1}))},getEvents:async(G)=>{let H="SELECT * FROM events WHERE 1=1",V=[];if(G.event_type)if(Array.isArray(G.event_type))H+=` AND type IN (${G.event_type.map(()=>"?").join(",")})`,V.push(...G.event_type);else H+=" AND type = ?",V.push(G.event_type);if(G.stream_type)if(Array.isArray(G.stream_type))H+=` AND stream_type IN (${G.stream_type.map(()=>"?").join(",")})`,V.push(...G.stream_type);else H+=" AND stream_type = ?",V.push(G.stream_type);if(G.stream_id)H+=" AND stream_id = ?",V.push(G.stream_id);if(G.after_sequence!==void 0)H+=" AND sequence_number > ?",V.push(G.after_sequence);return H+=" ORDER BY occurred_at ASC",this.db.prepare(H).all(...V).map((W)=>({sequence_number:W.sequence_number,event_id:W.id,event_type:W.type,stream_type:W.stream_type,stream_id:W.stream_id,data:JSON.parse(W.data),causation_id:W.causation_id,correlation_id:W.correlation_id,metadata:W.metadata?JSON.parse(W.metadata):void 0,occurred_at:W.occurred_at,recorded_at:W.occurred_at,schema_version:1}))},getLatestByStream:async(G,H)=>{let V=this.db.prepare(`
          SELECT * FROM events
          WHERE stream_type = ? AND stream_id = ?
          ORDER BY sequence_number DESC
          LIMIT 1
        `).get(G,H);return V?{sequence_number:V.sequence_number,event_id:V.id,event_type:V.type,stream_type:V.stream_type,stream_id:V.stream_id,data:JSON.parse(V.data),causation_id:V.causation_id,correlation_id:V.correlation_id,metadata:V.metadata?JSON.parse(V.metadata):void 0,occurred_at:V.occurred_at,recorded_at:V.occurred_at,schema_version:1}:null}},this.missions={},this.sorties={},this.checkpoints={},this.specialists={},this.messages={},K.checkpoints={version:"1.0.0",create:async(G)=>{let H=G.id||`chk_${Math.random().toString(36).substring(2,10)}`,V=new Date().toISOString();return this.db.prepare(`
          INSERT INTO checkpoints (
            id, mission_id, mission_title, timestamp, trigger, trigger_details,
            progress_percent, sorties, active_locks, pending_messages,
            recovery_context, created_by, expires_at, version, metadata
          ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        `).run(H,G.mission_id,G.mission_title||null,G.timestamp||V,G.trigger,G.trigger_details||null,G.progress_percent||0,JSON.stringify(G.sorties||[]),JSON.stringify(G.active_locks||[]),JSON.stringify(G.pending_messages||[]),JSON.stringify(G.recovery_context||{}),G.created_by,G.expires_at||null,G.version||"1.0.0",JSON.stringify(G.metadata||{})),await K.checkpoints.getById(H)},getById:async(G)=>{let H=this.db.prepare(`
          SELECT * FROM checkpoints WHERE id = ?
        `).get(G);if(!H)return null;return{id:H.id,mission_id:H.mission_id,mission_title:H.mission_title,timestamp:H.timestamp,trigger:H.trigger,trigger_details:H.trigger_details,progress_percent:H.progress_percent,sorties:H.sorties?JSON.parse(H.sorties):[],active_locks:H.active_locks?JSON.parse(H.active_locks):[],pending_messages:H.pending_messages?JSON.parse(H.pending_messages):[],recovery_context:H.recovery_context?JSON.parse(H.recovery_context):{},created_by:H.created_by,expires_at:H.expires_at,consumed_at:H.consumed_at,version:H.version,metadata:H.metadata?JSON.parse(H.metadata):{}}},getLatest:async(G)=>{let H=this.db.prepare(`
          SELECT * FROM checkpoints
          WHERE mission_id = ? AND consumed_at IS NULL
          ORDER BY timestamp DESC
          LIMIT 1
        `).get(G);if(!H)return null;return await K.checkpoints.getById(H.id)},list:async(G)=>{let H="SELECT * FROM checkpoints",V=[];if(G)H+=" WHERE mission_id = ?",V.push(G);return H+=" ORDER BY timestamp DESC",this.db.prepare(H).all(...V).map((W)=>({id:W.id,mission_id:W.mission_id,mission_title:W.mission_title,timestamp:W.timestamp,trigger:W.trigger,trigger_details:W.trigger_details,progress_percent:W.progress_percent,sorties:W.sorties?JSON.parse(W.sorties):[],active_locks:W.active_locks?JSON.parse(W.active_locks):[],pending_messages:W.pending_messages?JSON.parse(W.pending_messages):[],recovery_context:W.recovery_context?JSON.parse(W.recovery_context):{},created_by:W.created_by,expires_at:W.expires_at,consumed_at:W.consumed_at,version:W.version,metadata:W.metadata?JSON.parse(W.metadata):{}}))},delete:async(G)=>{return this.db.prepare(`
          DELETE FROM checkpoints WHERE id = ?
        `).run(G).changes>0},markConsumed:async(G)=>{let H=new Date().toISOString();if(this.db.prepare(`
          UPDATE checkpoints
          SET consumed_at = ?
          WHERE id = ?
        `).run(H,G).changes>0)return await K.checkpoints.getById(G);return null}}}async close(){try{if(this.db)this.db.close(),this.db=null,console.log(`SQLite database closed: ${this.dbPath}`)}catch(K){throw console.error("Error closing database:",K),K}}async isHealthy(){try{if(!this.db)return!1;return this.db.prepare("SELECT 1").get(),!0}catch{return!1}}async getStats(){if(!this.db)throw Error("Database not initialized");let K=this.db.prepare("SELECT COUNT(*) as count FROM events").get(),G=0,H=0,V=this.db.prepare("SELECT COUNT(*) as count FROM locks WHERE released_at IS NULL AND expires_at > datetime('now')").get(),Z=0,W=0,B=0;if(this.dbPath!==":memory:"&&T.existsSync(this.dbPath)){W=T.statSync(this.dbPath).size;let U=`${this.dbPath}-wal`;if(T.existsSync(U))B=T.statSync(U).size}return{total_events:K.count,total_missions:G,active_missions:H,active_locks:V.count,total_checkpoints:Z,database_size_bytes:W,wal_size_bytes:B}}async maintenance(){if(!this.db)throw Error("Database not initialized");try{this.db.exec("VACUUM"),console.log("Database maintenance completed")}catch(K){throw console.error("Error running database maintenance:",K),K}}async beginTransaction(){if(!this.db)throw Error("Database not initialized");try{this.db.exec("BEGIN TRANSACTION")}catch(K){throw console.error("Error beginning transaction:",K),K}}async commitTransaction(){if(!this.db)throw Error("Database not initialized");try{this.db.exec("COMMIT")}catch(K){throw console.error("Error committing transaction:",K),K}}async rollbackTransaction(){if(!this.db)throw Error("Database not initialized");try{this.db.exec("ROLLBACK")}catch(K){throw console.error("Error rolling back transaction:",K),K}}getDatabase(){return this.db}}var __dirname="/home/vitruvius/git/fleettools/squawk/src/db";function P(){return R.join(process.env.HOME||"",".local","share","fleet","squawk.json")}function v(){let K=R.join(process.env.HOME||"",".local","share","fleet","squawk.db"),G=R.dirname(K);try{if(!N.existsSync(G))N.mkdirSync(G,{recursive:!0});let H=R.join(G,".write-test");return N.writeFileSync(H,""),N.unlinkSync(H),console.log(`[Database] \u2713 Preferred path is writable: ${K}`),K}catch(H){let V=H instanceof Error?H.message:String(H);console.warn(`[Database] Preferred path not writable (${V})`),console.warn("[Database] Trying fallback path: /tmp/fleet/");let Z=R.join("/tmp","fleet",`squawk-${process.pid}.db`),W=R.dirname(Z);try{if(!N.existsSync(W))N.mkdirSync(W,{recursive:!0});let B=R.join(W,".write-test");return N.writeFileSync(B,""),N.unlinkSync(B),console.log(`[Database] \u2713 Fallback path is writable: ${Z}`),Z}catch(B){let U=B instanceof Error?B.message:String(B);return console.warn(`[Database] Fallback path also not writable (${U})`),console.warn("[Database] Using in-memory database as last resort"),":memory:"}}}var Q=null;async function A(K){console.log("[Database] Determining database path...");let G=K||v();if(console.log(`[Database] Using database path: ${G}`),G!==":memory:"){let Z=R.dirname(G);try{if(!N.existsSync(Z))console.log(`[Database] Creating directory: ${Z}`),N.mkdirSync(Z,{recursive:!0})}catch(W){console.warn(`[Database] Warning: Could not create directory ${Z}, attempting with selected path anyway`),console.warn(`[Database] Error: ${W instanceof Error?W.message:String(W)}`)}}console.log("[Database] Initializing SQLite adapter...");let H=R.join(__dirname,"schema.sql");Q=new S(G,H),await Q.initialize(),console.log("[Database] \u2713 Adapter initialized successfully");let V=P();if(N.existsSync(V)){await q(V);let Z=V+".backup";N.renameSync(V,Z),console.log("[Migration] Legacy data migrated to SQLite"),console.log(`[Migration] Backup saved to: ${Z}`)}}function Y(){if(!Q)throw Error("Database not initialized. Call initializeDatabase() first.");return Q}async function D(){if(Q)await Q.close(),Q=null}async function q(K){console.log(`[Migration] Starting migration from: ${K}`);try{let G=N.readFileSync(K,"utf-8"),H=JSON.parse(G),V={mailboxes:0,events:0,cursors:0,locks:0};for(let[Z,W]of Object.entries(H.mailboxes||{}))try{if(!W.created_at||!W.updated_at){console.warn(`[Migration] Skipping mailbox ${Z} due to missing required fields`);continue}await Q.mailboxes.create({id:Z,created_at:W.created_at,updated_at:W.updated_at}),V.mailboxes++}catch(B){console.warn(`[Migration] Failed to migrate mailbox ${Z}:`,B)}for(let[Z,W]of Object.entries(H.events||{})){if(!await Q.mailboxes.getById(Z))await Q.mailboxes.create({id:Z,created_at:new Date().toISOString(),updated_at:new Date().toISOString()}),V.mailboxes++;for(let B of W)try{if(!B.type){console.warn(`[Migration] Skipping event without type field in mailbox ${Z}`);continue}await Q.events.append({event_type:B.type,stream_type:"squawk",stream_id:Z,data:typeof B.data==="string"?JSON.parse(B.data):B.data,occurred_at:B.occurred_at,causation_id:B.causation_id,correlation_id:B.correlation_id,metadata:B.metadata?typeof B.metadata==="string"?JSON.parse(B.metadata):B.metadata:void 0}),V.events++}catch(U){console.warn("[Migration] Failed to migrate event:",U)}}for(let[Z,W]of Object.entries(H.cursors||{}))try{await Q.cursors.create({id:Z,stream_type:"squawk",stream_id:W.stream_id,position:W.position,consumer_id:W.consumer_id||"migrated"}),V.cursors++}catch(B){console.warn(`[Migration] Failed to migrate cursor ${Z}:`,B)}for(let[Z,W]of Object.entries(H.locks||{})){let B=W;if(!B.released_at)try{await Q.locks.acquire({file:B.file,specialist_id:B.reserved_by,timeout_ms:B.timeout_ms||30000,purpose:B.purpose==="delete"?"delete":B.purpose==="read"?"read":"edit",checksum:B.checksum}),V.locks++}catch(U){console.warn(`[Migration] Failed to migrate lock ${Z}:`,U)}}console.log("[Migration] Complete:"),console.log(`  - Mailboxes: ${V.mailboxes}`),console.log(`  - Events: ${V.events}`),console.log(`  - Cursors: ${V.cursors}`),console.log(`  - Locks: ${V.locks}`)}catch(G){throw console.error("[Migration] Failed:",G),G}}var E={getAll:async()=>{return(await Y().mailboxes.getAll()).sort((H,V)=>new Date(V.created_at).getTime()-new Date(H.created_at).getTime())},getById:async(K)=>{return Y().mailboxes.getById(K)},create:async(K)=>{let G=Y(),H=new Date().toISOString();return G.mailboxes.create({id:K,created_at:H,updated_at:H})},exists:async(K)=>{return await Y().mailboxes.getById(K)!==null}},O={getByMailbox:async(K)=>{return(await Y().events.queryByStream("squawk",K)).sort((V,Z)=>new Date(V.occurred_at).getTime()-new Date(Z.occurred_at).getTime())},append:async(K,G)=>{let H=Y();if(!await H.mailboxes.getById(K))await H.mailboxes.create({id:K,created_at:new Date().toISOString(),updated_at:new Date().toISOString()});let V=[];for(let Z of G){let W=await H.events.append({event_type:Z.type,stream_type:"squawk",stream_id:K,data:typeof Z.data==="string"?JSON.parse(Z.data):Z.data,occurred_at:Z.occurred_at,causation_id:Z.causation_id,correlation_id:Z.correlation_id,metadata:Z.metadata?typeof Z.metadata==="string"?JSON.parse(Z.metadata):Z.metadata:void 0});V.push(W)}return V}},_={getById:async(K)=>{return Y().cursors.getById(K)},getByStream:async(K)=>{return(await Y().cursors.getAll()).find((V)=>V.stream_id===K)||null},upsert:async(K)=>{let G=Y(),H=K.id||`${K.stream_id}_cursor`,V=new Date().toISOString(),Z=await G.cursors.getById(H);if(Z)return await G.cursors.update(H,{position:K.position,updated_at:V}),Z;else return G.cursors.create({id:H,stream_type:"squawk",stream_id:K.stream_id,position:K.position,consumer_id:K.consumer_id||"default"})}},C={getAll:async()=>{let G=await Y().locks.getAll(),H=new Date().toISOString();return G.filter((V)=>{if(V.status==="released")return!1;return V.expires_at>H})},getById:async(K)=>{return Y().locks.getById(K)},acquire:async(K)=>{let H=await Y().locks.acquire({file:K.file,specialist_id:K.reserved_by||K.specialist_id,timeout_ms:K.timeout_ms||30000,purpose:K.purpose==="delete"?"delete":K.purpose==="read"?"read":"edit",checksum:K.checksum});if(H.conflict)return H.existing_lock||{id:H.lock?.id||"",file:K.file,reserved_by:H.lock?.reserved_by||"",reserved_at:H.lock?.reserved_at||"",released_at:null,purpose:K.purpose||"edit",checksum:K.checksum,timeout_ms:K.timeout_ms||30000,metadata:K.metadata};return H.lock},release:async(K)=>{let G=Y(),H=await G.locks.getById(K);if(H)return await G.locks.release(K),H;return null},getExpired:async()=>{let G=await Y().locks.getAll(),H=new Date().toISOString();return G.filter((V)=>{if(V.status==="released")return!1;return V.expires_at<=H})},releaseExpired:async()=>{let K=await C.getExpired();for(let G of K)await C.release(G.id);return K.length}};async function y(K={}){let G=K.port||parseInt(process.env.SQUAWK_PORT||"3000",10);await A(),console.log("Squawk API database initialized");let H=Bun.serve({port:G,async fetch(W){let U=new URL(W.url).pathname,X={"Access-Control-Allow-Origin":"*","Access-Control-Allow-Methods":"GET, POST, PUT, DELETE, OPTIONS","Access-Control-Allow-Headers":"Content-Type"};if(W.method==="OPTIONS")return new Response(null,{headers:X});if(U==="/health")return new Response(JSON.stringify({status:"healthy",service:"squawk",timestamp:new Date().toISOString()}),{headers:{...X,"Content-Type":"application/json"}});if(U==="/api/v1/mailbox/append"&&W.method==="POST")try{let $=await W.json(),{stream_id:J,events:z}=$;if(!J||!Array.isArray(z))return new Response(JSON.stringify({error:"stream_id and events array are required"}),{status:400,headers:{...X,"Content-Type":"application/json"}});if(!await E.exists(J))await E.create(J);let M=z.map((j)=>({type:j.type,stream_id:J,data:JSON.stringify(j.data),occurred_at:new Date().toISOString(),causation_id:j.causation_id||null,metadata:j.metadata?JSON.stringify(j.metadata):null})),L=await O.append(J,M),x=await E.getById(J),g=await O.getByMailbox(J);return new Response(JSON.stringify({mailbox:{...x,events:g},inserted:L.length}),{headers:{...X,"Content-Type":"application/json"}})}catch($){console.error("Error appending to mailbox:",$),K.onRequestError?.($);let J=$ instanceof Error?$.message:String($);return new Response(JSON.stringify({error:"Failed to append to mailbox",details:J}),{status:500,headers:{...X,"Content-Type":"application/json"}})}if(U.startsWith("/api/v1/mailbox/")&&W.method==="GET"){let $=U.split("/").pop();if(!$)return new Response(JSON.stringify({error:"Invalid stream ID"}),{status:400,headers:{...X,"Content-Type":"application/json"}});try{let J=await E.getById($);if(!J)return new Response(JSON.stringify({error:"Mailbox not found"}),{status:404,headers:{...X,"Content-Type":"application/json"}});let z=await O.getByMailbox($);return new Response(JSON.stringify({mailbox:{...J,events:z}}),{headers:{...X,"Content-Type":"application/json"}})}catch(J){return console.error("Error getting mailbox:",J),K.onRequestError?.(J),new Response(JSON.stringify({error:"Failed to get mailbox"}),{status:500,headers:{...X,"Content-Type":"application/json"}})}}if(U==="/api/v1/cursor/advance"&&W.method==="POST")try{let $=await W.json(),{stream_id:J,position:z}=$;if(!J||typeof z!=="number")return new Response(JSON.stringify({error:"stream_id and position are required"}),{status:400,headers:{...X,"Content-Type":"application/json"}});if(!await E.exists(J))await E.create(J);let M=await _.upsert({stream_id:J,position:z,updated_at:new Date().toISOString()});return new Response(JSON.stringify({cursor:M}),{headers:{...X,"Content-Type":"application/json"}})}catch($){return console.error("Error advancing cursor:",$),K.onRequestError?.($),new Response(JSON.stringify({error:"Failed to advance cursor"}),{status:500,headers:{...X,"Content-Type":"application/json"}})}if(U.startsWith("/api/v1/cursor/")&&W.method==="GET"){let $=U.split("/").pop();if(!$)return new Response(JSON.stringify({error:"Invalid cursor ID"}),{status:400,headers:{...X,"Content-Type":"application/json"}});try{let J=await _.getById($);if(!J)return new Response(JSON.stringify({error:"Cursor not found"}),{status:404,headers:{...X,"Content-Type":"application/json"}});return new Response(JSON.stringify({cursor:J}),{headers:{...X,"Content-Type":"application/json"}})}catch(J){return console.error("Error getting cursor:",J),K.onRequestError?.(J),new Response(JSON.stringify({error:"Failed to get cursor"}),{status:500,headers:{...X,"Content-Type":"application/json"}})}}if(U==="/api/v1/lock/acquire"&&W.method==="POST")try{let $=await W.json(),{file:J,specialist_id:z,timeout_ms:M=30000}=$;if(!J||!z)return new Response(JSON.stringify({error:"file and specialist_id are required"}),{status:400,headers:{...X,"Content-Type":"application/json"}});let L=await C.acquire({file:J,reserved_by:z,reserved_at:new Date().toISOString(),released_at:null,purpose:"edit",checksum:null,timeout_ms:M,metadata:null});return new Response(JSON.stringify({lock:L}),{headers:{...X,"Content-Type":"application/json"}})}catch($){return console.error("Error acquiring lock:",$),K.onRequestError?.($),new Response(JSON.stringify({error:"Failed to acquire lock"}),{status:500,headers:{...X,"Content-Type":"application/json"}})}if(U==="/api/v1/lock/release"&&W.method==="POST")try{let $=await W.json(),{lock_id:J,specialist_id:z}=$;if(!J)return new Response(JSON.stringify({error:"lock_id is required"}),{status:400,headers:{...X,"Content-Type":"application/json"}});let M=await C.getById(J);if(!M)return new Response(JSON.stringify({error:"Lock not found"}),{status:404,headers:{...X,"Content-Type":"application/json"}});if(M.reserved_by!==z)return new Response(JSON.stringify({error:"Cannot release lock: wrong specialist"}),{status:403,headers:{...X,"Content-Type":"application/json"}});let L=await C.release(J);return new Response(JSON.stringify({lock:L}),{headers:{...X,"Content-Type":"application/json"}})}catch($){return console.error("Error releasing lock:",$),K.onRequestError?.($),new Response(JSON.stringify({error:"Failed to release lock"}),{status:500,headers:{...X,"Content-Type":"application/json"}})}if(U==="/api/v1/locks"&&W.method==="GET")try{let $=await C.getAll();return new Response(JSON.stringify({locks:$}),{headers:{...X,"Content-Type":"application/json"}})}catch($){return console.error("Error listing locks:",$),K.onRequestError?.($),new Response(JSON.stringify({error:"Failed to list locks"}),{status:500,headers:{...X,"Content-Type":"application/json"}})}if(U==="/api/v1/coordinator/status"&&W.method==="GET")try{let $=await E.getAll(),J=await C.getAll();return new Response(JSON.stringify({active_mailboxes:$.length,active_locks:J.length,timestamp:new Date().toISOString()}),{headers:{...X,"Content-Type":"application/json"}})}catch($){console.error("Error getting coordinator status:",$),K.onRequestError?.($);let J=$ instanceof Error?$.message:String($);return new Response(JSON.stringify({error:"Failed to get status",details:J}),{status:500,headers:{...X,"Content-Type":"application/json"}})}return new Response(JSON.stringify({error:"Not found"}),{status:404,headers:{...X,"Content-Type":"application/json"}})}}),V=setInterval(async()=>{let W=await C.releaseExpired();if(W>0)console.log(`Released ${W} expired locks`)},30000);console.log(`Squawk API server listening on port ${H.port}`),console.log("Endpoints:"),console.log("  POST   /api/v1/mailbox/append   - Append events to mailbox"),console.log("  GET    /api/v1/mailbox/:streamId - Get mailbox contents"),console.log("  POST   /api/v1/cursor/advance   - Advance cursor position"),console.log("  GET    /api/v1/cursor/:cursorId - Get cursor position"),console.log("  POST   /api/v1/lock/acquire     - Acquire file lock (CTK)"),console.log("  POST   /api/v1/lock/release    - Release file lock (CTK)"),console.log("  GET    /api/v1/locks               - List all active locks"),console.log("  GET    /api/v1/coordinator/status - Get coordinator status"),console.log("  GET    /health                     - Health check");let Z=(W)=>{console.log(`Received ${W}, shutting down...`),clearInterval(V),D(),H.stop(),process.exit(0)};process.on("SIGINT",()=>Z("SIGINT")),process.on("SIGTERM",()=>Z("SIGTERM")),K.onReady?.(H.port)}y({port:parseInt(process.env.SQUAWK_PORT||"3000",10),onReady:(K)=>{console.log(`Squawk server is ready on port ${K}`)},onRequestError:(K)=>{console.error("Request error:",K)}}).catch((K)=>{console.error("Failed to start Squawk server:",K),process.exit(1)});
